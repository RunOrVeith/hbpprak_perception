{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable global logging from the virtual coach\n",
    "import logging\n",
    "logging.disable(logging.INFO)\n",
    "logging.getLogger('rospy').propagate = False\n",
    "logging.getLogger('rosout').propagate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: [2018-01-28 15:27:24,639 - VirtualCoach] No OIDC username supplied, simulation services will fail if OIDC is enabled in this environment (local).\n"
     ]
    }
   ],
   "source": [
    "# log into the virtual coach, update with your credentials\n",
    "try:\n",
    "    from hbp_nrp_virtual_coach.virtual_coach import VirtualCoach\n",
    "    vc = VirtualCoach(environment='local')\n",
    "except ImportError as e:\n",
    "    print(e)\n",
    "    print(\"You have to start this notebook with the command:\\\n",
    "          cle-virtual-coach jupyter notebook\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_template = '''\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Thimblerigger solver\n",
    "\"\"\"\n",
    "\n",
    "# pragma: no cover\n",
    "__author__ = 'Veith Roethlingshoefer'\n",
    "\n",
    "from hbp_nrp_cle.brainsim import simulator as sim\n",
    "import numpy as np\n",
    "\n",
    "n_grid = 3*3\n",
    "n_out = 3\n",
    "\n",
    "grid = sim.Population(n_grid, cellclass=sim.IF_curr_exp())\n",
    "output = sim.Population(n_out, cellclass=sim.IF_curr_exp())\n",
    "sim.Projection(grid[3, 4, 5], output, sim.AllToAllConnector(),\n",
    "               sim.StaticSynapse(weight={syn_weight}))  \n",
    "circuit = grid + output\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_to_brain = \"\"\"\n",
    "from std_msgs.msg import Int8, UInt32MultiArray\n",
    "import numpy as np\n",
    "\n",
    "@nrp.MapRobotSubscriber(\"grid_seen\", Topic(\"/thimblerigger_solver/grid_activations\", UInt32MultiArray))\n",
    "@nrp.MapSpikeSource(\"grid_neurons\", nrp.map_neurons(range(0, 9), lambda i: nrp.brain.sensors[i]), nrp.poisson)\n",
    "@nrp.Robot2Neuron()\n",
    "def feed_brain(t, grid_seen, grid_neurons):\n",
    "    grid = grid_seen.value\n",
    "    if grid is not None:\n",
    "        grid = np.array(grid.data, dtype=np.uint32)\n",
    "        grid = grid.astype(np.float32)\n",
    "        # There is some version problem with pynn and passing numpy arrays, so we need to loop over entries\n",
    "        for i, neuron in enumerate(grid_neurons):\n",
    "            neuron.rate = grid[i]\n",
    "        #grid_neurons.rate = grid\n",
    "        clientLogger.info(grid)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_success_csv = \"\"\"\n",
    "from std_msgs.msg import Int8\n",
    "import numpy as np\n",
    "\n",
    "@nrp.MapCSVRecorder(\"index_recorder\", filename=\"index_real_estimate.csv\",\n",
    "                    headers=[\"Time\", \"real\", \"estimate\"])\n",
    "@nrp.MapSpikeSink(\"left\", nrp.brain.actors[0], nrp.spike_recorder)\n",
    "@nrp.MapSpikeSink(\"middle\", nrp.brain.actors[1], nrp.spike_recorder)\n",
    "@nrp.MapSpikeSink(\"right\", nrp.brain.actors[2], nrp.spike_recorder)\n",
    "@nrp.Robot2Neuron()\n",
    "def record_index_csv(t, index_recorder,  left, middle, right):\n",
    "\n",
    "   \n",
    "    clientLogger.info(left.spiked, middle.spiked, right.spiked)\n",
    "        \n",
    "    #index_recorder.record_entry(t,\n",
    "    #                            training_signal,\n",
    "    #                            np.argmax(output_neurons))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import rospy\n",
    "import time\n",
    "from cv_bridge import CvBridge\n",
    "import sensor_msgs\n",
    "import std_msgs\n",
    "from gazebo_msgs.srv import GetModelState, SetModelState\n",
    "from gazebo_msgs.msg import ModelState\n",
    "from thread import start_new_thread\n",
    "import math\n",
    "import thimblerigger_config as tc\n",
    "from std_srvs.srv import Trigger, TriggerResponse\n",
    "from std_msgs.msg import UInt32MultiArray\n",
    "from std_msgs.msg import MultiArrayDimension\n",
    "import tempfile\n",
    "import os\n",
    "import csv\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "class RobotMover(object):\n",
    "\n",
    "    def __init__(self, model_name=\"robot\"):\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def go_to_pose(self, x, y, orientation):\n",
    "        pass\n",
    "\n",
    "\n",
    "class TeleportRobotMover(RobotMover):\n",
    "\n",
    "    def __init__(self, model_name=\"robot\"):\n",
    "        self.get_position = rospy.ServiceProxy(\"/gazebo/get_model_state\", GetModelState)\n",
    "        self.set_position = rospy.ServiceProxy(\"/gazebo/set_model_state\", SetModelState)\n",
    "        super(TeleportRobotMover, self).__init__(model_name=model_name)\n",
    "\n",
    "    def go_to_pose(self, x, y, orientation):\n",
    "        current_robot_pose = self.get_position(self.model_name, \"\")\n",
    "        new_state = ModelState()\n",
    "        new_state.model_name = self.model_name\n",
    "        new_state.pose = current_robot_pose.pose\n",
    "        new_state.scale = current_robot_pose.scale\n",
    "        new_state.twist = current_robot_pose.twist\n",
    "        new_state.pose.position.x = x\n",
    "        new_state.pose.position.y = y\n",
    "        new_state.pose.orientation.x = orientation[1]\n",
    "        new_state.pose.orientation.y = orientation[2]\n",
    "        new_state.pose.orientation.z = orientation[3]\n",
    "        new_state.pose.orientation.w = orientation[0]\n",
    "        new_state.reference_frame = \"world\"\n",
    "        self.set_position(new_state)\n",
    "\n",
    "\n",
    "class ChallengeInteractor(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        rospy.wait_for_service(tc.thimblerigger_show_correct_service, 10)\n",
    "        print(\"Show mug service available...\")\n",
    "        rospy.wait_for_service(tc.thimblerigger_hide_correct_service, 10)\n",
    "        print(\"Hide mug service available...\")\n",
    "        rospy.wait_for_service(tc.thimblerigger_shuffle_service, 10)\n",
    "        print(\"Shuffle service available...\")\n",
    "        print(\"All thimblerigger services found.\")                       \n",
    "        self.show_correct_mug = rospy.ServiceProxy(tc.thimblerigger_show_correct_service, Trigger)\n",
    "        self.hide_correct_mug = rospy.ServiceProxy(tc.thimblerigger_hide_correct_service, Trigger)\n",
    "        self.shuffle = rospy.ServiceProxy(tc.thimblerigger_shuffle_service, Trigger)\n",
    "\n",
    "                               \n",
    "class Solver(object):\n",
    "\n",
    "    def __init__(self, sim, data_dir):\n",
    "        \n",
    "        \n",
    "        self.neuron_grid = None\n",
    "        self.define_neuron_grid = False\n",
    "\n",
    "        self.sim = sim\n",
    "        self.sim.add_transfer_function(record_success_csv)\n",
    "        self.sim.start()\n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "        self.estimate = [False] * 3\n",
    "        self.center_points = None\n",
    "        self.robot_mover = TeleportRobotMover()\n",
    "        self.current_view = \"front\"\n",
    "        self.challenge = ChallengeInteractor()\n",
    "\n",
    "        self.set_joints_start()\n",
    "        print(\"Moved robot to start pose\")\n",
    "        self.activations = rospy.Publisher('/thimblerigger_solver/grid_activations', UInt32MultiArray, queue_size=5)\n",
    "        print(\"Created activations publisher\")\n",
    "        self.view = rospy.Subscriber(\"/icub_model/left_eye_camera/image_raw\", sensor_msgs.msg.Image, self.extract_mugs)\n",
    "        print(\"Subscribed to robot view.\")\n",
    "        #self.send_grid_neuron_activations()  # Set all rates to 0 to list this topic\n",
    "        self.sim.add_transfer_function(grid_to_brain)\n",
    "\n",
    "\n",
    "\n",
    "    def set_joints_start(self):\n",
    "        neck = rospy.Publisher(\"/robot/neck_pitch/pos\", std_msgs.msg.Float64, queue_size=1)\n",
    "        l_elbow = rospy.Publisher(\"/robot/l_elbow/pos\", std_msgs.msg.Float64, queue_size=1)\n",
    "        r_elbow = rospy.Publisher(\"/robot/r_elbow/pos\", std_msgs.msg.Float64, queue_size=1)\n",
    "        def lower_gaze_and_arms():\n",
    "            while not rospy.is_shutdown():\n",
    "                neck.publish(std_msgs.msg.Float64(-0.8))\n",
    "                l_elbow.publish(std_msgs.msg.Float64(-25.0))\n",
    "                r_elbow.publish(std_msgs.msg.Float64(-25.0))\n",
    "            l_elbow.unregister()\n",
    "            r_elbow.unregister()\n",
    "        start_new_thread(lower_gaze_and_arms, ())\n",
    "        time.sleep(2)\n",
    "        self.side_look()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        print(\"Closing windows...\")\n",
    "        self.sim.pause()\n",
    "        with open(os.path.join(self.data_dir, \"index_real_estimate.csv\"), 'wb') as f:\n",
    "            cf = csv.writer(f)\n",
    "            csv_data = self.sim.get_csv_data(\"index_real_estimate.csv\")\n",
    "            cf.writerows(csv_data)\n",
    "            \n",
    "        if self.view is not None:\n",
    "            print(\"unregistering image callback\")\n",
    "            self.view.unregister()\n",
    "        self.activations.unregister()\n",
    "        # Apparently closing the cv2 windows crashes the jupyter kernel\n",
    "        #cv2.destroyWindow(\"Robot extracted view\")\n",
    "        #cv2.waitKey(1)\n",
    "        self.sim.stop()\n",
    "\n",
    "        print(\"destroying the solver...\")\n",
    "\n",
    "\n",
    "    def front_look(self):\n",
    "        self.current_view = \"front\"\n",
    "        self.robot_mover.go_to_pose(x=-0.75, y=0., orientation=(0, 0, 1, 0))\n",
    "\n",
    "    def side_look(self):\n",
    "        self.current_view = \"side\"\n",
    "        orientation = (math.sqrt(0.5), 0, 0, -math.sqrt(0.5))\n",
    "        self.robot_mover.go_to_pose(x=0.4, y=-0.9, orientation=orientation)\n",
    "\n",
    "    def allow_define_neuron_grid(self):\n",
    "        self.define_neuron_grid = True\n",
    "\n",
    "    def find_neuron_grid(self, contours):\n",
    "        if self.center_points is None or self.center_points.shape != (3, 2):\n",
    "            return\n",
    "        \n",
    "        x_intervals = [int(self.center_points[0, 0] + 0.5 * \\\n",
    "                        (self.center_points[1, 0] - self.center_points[0, 0])),\n",
    "                       int(self.center_points[1, 0] + 0.5 * \\\n",
    "                        (self.center_points[2, 0] - self.center_points[1, 0]))]\n",
    "        y_intervals = []\n",
    "        for cnt in contours:\n",
    "            (_,y),radius = cv2.minEnclosingCircle(cnt)\n",
    "            y_intervals.extend([int(y + 1.5 * radius), int(y - 1.5 * radius)])\n",
    "        y_intervals = [min(y_intervals), max(y_intervals)]\n",
    "        self.neuron_grid = x_intervals, y_intervals\n",
    "        self.define_neuron_grid = False\n",
    "        print(\"Neuron grid defined\")\n",
    "\n",
    "\n",
    "    def send_grid_neuron_activations(self):\n",
    "        locations = np.zeros((3,3))\n",
    "        if self.neuron_grid is not None:\n",
    "            for center in self.center_points:\n",
    "                x_idx = np.searchsorted(self.neuron_grid[0], center[0])\n",
    "                y_idx = np.searchsorted(self.neuron_grid[1], center[1])\n",
    "                locations[y_idx, x_idx] = 200\n",
    "            if True in self.estimate:\n",
    "                locations[1, self.estimate.index(True)] = 500\n",
    "  \n",
    "        mat = UInt32MultiArray()\n",
    "        mat.layout.dim.append(MultiArrayDimension())\n",
    "        mat.layout.dim.append(MultiArrayDimension())\n",
    "        mat.layout.dim[0].label = \"height\"\n",
    "        mat.layout.dim[1].label = \"width\"\n",
    "        mat.layout.dim[0].size = 3\n",
    "        mat.layout.dim[1].size = 3\n",
    "        mat.layout.dim[0].stride = 3*3\n",
    "        mat.layout.dim[1].stride = 3\n",
    "        mat.layout.data_offset = 0\n",
    "        mat.data = list(locations.flatten())\n",
    "        self.activations.publish(mat)\n",
    "                \n",
    "\n",
    "\n",
    "    def extract_mugs(self, img_msg, contour_thresh=50, visualize=False):\n",
    "        img = CvBridge().imgmsg_to_cv2(img_msg, \"bgr8\")\n",
    "        most_vibrant_channel = np.argmax(img, axis=2)\n",
    "        img[most_vibrant_channel != 2] = 0\n",
    "        img[img[:,:,2] < 150] = 0\n",
    "        red = img[:, :, 2]\n",
    "        _, thresh = cv2.threshold(red, 150, 255, 0)\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        thresh = cv2.erode(thresh, kernel,iterations = 1)\n",
    "        im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = [c for c in contours if cv2.contourArea(c) > contour_thresh]\n",
    "\n",
    "        moments = [cv2.moments(c) for c in contours]\n",
    "        centers = sorted([(int(M['m10']/M['m00']), int(M['m01']/M['m00'])) for M in moments])\n",
    "        self.center_points = np.array(centers)\n",
    "\n",
    "\n",
    "        if self.define_neuron_grid and self.neuron_grid is None:\n",
    "            self.find_neuron_grid(contours)\n",
    "\n",
    "        self.send_grid_neuron_activations()\n",
    "\n",
    "\n",
    "        if visualize:\n",
    "            if self.neuron_grid is not None:\n",
    "                for point_x in self.neuron_grid[0]:\n",
    "                    cv2.line(img, (point_x, 0), (point_x, img.shape[0]), color=(255, 0, 0))\n",
    "                for point_y in self.neuron_grid[1]:\n",
    "                    cv2.line(img, (0, point_y), (img.shape[1], point_y), color=(255, 0, 0))\n",
    "            #for center in centers:\n",
    "            #    cv2.circle(img, center, radius=1, color=(255,0,0), thickness=3 )\n",
    "            #cv2.drawContours(img, contours, -1, (0,255,0), 3)\n",
    "            cv2.imshow(\"Robot extracted view\", img)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "    def find_correct_mug_beginning(self):\n",
    "        self.allow_define_neuron_grid()\n",
    "        self.challenge.show_correct_mug()\n",
    "        print(\"checking which mug contains the ball\")\n",
    "        correct_mug_id = np.argmin(np.transpose(self.center_points), axis=1)[1]\n",
    "        self.estimate[correct_mug_id] = True\n",
    "        print(\"Found this mug layout: \", self.estimate)\n",
    "        self.challenge.hide_correct_mug()\n",
    "        print(\"found correct mug beginning.\")\n",
    "        \n",
    "    def shuffle(self):\n",
    "        print(\"Shuffling mugs now\")\n",
    "        self.challenge.shuffle()\n",
    "\n",
    "    def verify_guess(self):\n",
    "        self.side_look()\n",
    "        self.challenge.show_correct_mug()\n",
    "        correct_mug_id = np.argmin(np.transpose(self.center_points), axis=1)[1]\n",
    "        self.challenge.hide_correct_mug()\n",
    "        return self.estimate.index(True) == correct_mug_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(data_dir, brain_params={'syn_weight': 1.0}):\n",
    "    sim = vc.launch_experiment('ExDPerceptionChallengeKIT')\n",
    "    brain_file = brain_template.format(**brain_params)\n",
    "    #sim.edit_brain(brain_file)\n",
    "    solver = Solver(sim, data_dir)\n",
    "    solver.find_correct_mug_beginning()\n",
    "    solver.shuffle()\n",
    "    return solver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'gzweb': {u'assets': u'http://localhost:8080/assets',\n",
      "             u'nrp-services': u'http://localhost:8080',\n",
      "             u'videoStreaming': u'http://localhost:8080/webstream/',\n",
      "             u'websocket': u'ws://localhost:8080/gzbridge'},\n",
      "  u'id': u'localhost',\n",
      "  u'rosbridge': {u'websocket': u'ws://localhost:8080/rosbridge'},\n",
      "  u'serverJobLocation': u'local'}]\n",
      "Show mug service available...\n",
      "Hide mug service available...\n",
      "Shuffle service available...\n",
      "All thimblerigger services found.\n",
      "Moved robot to start pose\n",
      "Created activations publisher\n",
      "Subscribed to robot view.\n",
      "Neuron grid defined\n",
      "checking which mug contains the ball\n",
      "('Found this mug layout: ', [True, False, False])\n",
      "found correct mug beginning.\n",
      "Shuffling mugs now\n"
     ]
    }
   ],
   "source": [
    "tmp_folder = tempfile.mkdtemp()\n",
    "solver = run_experiment(data_dir=tmp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling mugs now\n"
     ]
    }
   ],
   "source": [
    "solver.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing windows...\n",
      "unregistering image callback\n",
      "WARNING: [2018-01-26 15:35:26,449 - rosout] Could not process inbound connection: [/virtual_coach] is not a publisher of [/thimblerigger_solver/grid_activations]. Topics are [['/robot/neck_pitch/pos', 'std_msgs/Float64'], ['/robot/r_elbow/pos', 'std_msgs/Float64'], ['/rosout', 'rosgraph_msgs/Log'], ['/robot/l_elbow/pos', 'std_msgs/Float64']]{'message_definition': '# Please look at the MultiArrayLayout message definition for\\n# documentation on all multiarrays.\\n\\nMultiArrayLayout  layout        # specification of data layout\\nuint32[]          data          # array of data\\n\\n\\n================================================================================\\nMSG: std_msgs/MultiArrayLayout\\n# The multiarray declares a generic multi-dimensional array of a\\n# particular data type.  Dimensions are ordered from outer most\\n# to inner most.\\n\\nMultiArrayDimension[] dim # Array of dimension properties\\nuint32 data_offset        # padding elements at front of data\\n\\n# Accessors should ALWAYS be written in terms of dimension stride\\n# and specified outer-most dimension first.\\n# \\n# multiarray(i,j,k) = data[data_offset + dim_stride[1]*i + dim_stride[2]*j + k]\\n#\\n# A standard, 3-channel 640x480 image with interleaved color channels\\n# would be specified as:\\n#\\n# dim[0].label  = \"height\"\\n# dim[0].size   = 480\\n# dim[0].stride = 3*640*480 = 921600  (note dim[0] stride is just size of image)\\n# dim[1].label  = \"width\"\\n# dim[1].size   = 640\\n# dim[1].stride = 3*640 = 1920\\n# dim[2].label  = \"channel\"\\n# dim[2].size   = 3\\n# dim[2].stride = 3\\n#\\n# multiarray(i,j,k) refers to the ith row, jth column, and kth channel.\\n\\n================================================================================\\nMSG: std_msgs/MultiArrayDimension\\nstring label   # label of given dimension\\nuint32 size    # size of given dimension (in type units)\\nuint32 stride  # stride of given dimension', 'callerid': '/ros_cle_simulation_31594_1516976831299', 'tcp_nodelay': '0', 'md5sum': '4d6a180abc9be191b96a7eda6c8a233d', 'topic': '/thimblerigger_solver/grid_activations', 'type': 'std_msgs/UInt32MultiArray'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARN] [1516977326.449492, 186.601000]: Could not process inbound connection: [/virtual_coach] is not a publisher of [/thimblerigger_solver/grid_activations]. Topics are [['/robot/neck_pitch/pos', 'std_msgs/Float64'], ['/robot/r_elbow/pos', 'std_msgs/Float64'], ['/rosout', 'rosgraph_msgs/Log'], ['/robot/l_elbow/pos', 'std_msgs/Float64']]{'message_definition': '# Please look at the MultiArrayLayout message definition for\\n# documentation on all multiarrays.\\n\\nMultiArrayLayout  layout        # specification of data layout\\nuint32[]          data          # array of data\\n\\n\\n================================================================================\\nMSG: std_msgs/MultiArrayLayout\\n# The multiarray declares a generic multi-dimensional array of a\\n# particular data type.  Dimensions are ordered from outer most\\n# to inner most.\\n\\nMultiArrayDimension[] dim # Array of dimension properties\\nuint32 data_offset        # padding elements at front of data\\n\\n# Accessors should ALWAYS be written in terms of dimension stride\\n# and specified outer-most dimension first.\\n# \\n# multiarray(i,j,k) = data[data_offset + dim_stride[1]*i + dim_stride[2]*j + k]\\n#\\n# A standard, 3-channel 640x480 image with interleaved color channels\\n# would be specified as:\\n#\\n# dim[0].label  = \"height\"\\n# dim[0].size   = 480\\n# dim[0].stride = 3*640*480 = 921600  (note dim[0] stride is just size of image)\\n# dim[1].label  = \"width\"\\n# dim[1].size   = 640\\n# dim[1].stride = 3*640 = 1920\\n# dim[2].label  = \"channel\"\\n# dim[2].size   = 3\\n# dim[2].stride = 3\\n#\\n# multiarray(i,j,k) refers to the ith row, jth column, and kth channel.\\n\\n================================================================================\\nMSG: std_msgs/MultiArrayDimension\\nstring label   # label of given dimension\\nuint32 size    # size of given dimension (in type units)\\nuint32 stride  # stride of given dimension', 'callerid': '/ros_cle_simulation_31594_1516976831299', 'tcp_nodelay': '0', 'md5sum': '4d6a180abc9be191b96a7eda6c8a233d', 'topic': '/thimblerigger_solver/grid_activations', 'type': 'std_msgs/UInt32MultiArray'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: [2018-01-26 15:35:27,450 - rosout] Could not process inbound connection: [/virtual_coach] is not a publisher of [/thimblerigger_solver/grid_activations]. Topics are [['/robot/neck_pitch/pos', 'std_msgs/Float64'], ['/robot/r_elbow/pos', 'std_msgs/Float64'], ['/rosout', 'rosgraph_msgs/Log'], ['/robot/l_elbow/pos', 'std_msgs/Float64']]{'message_definition': '# Please look at the MultiArrayLayout message definition for\\n# documentation on all multiarrays.\\n\\nMultiArrayLayout  layout        # specification of data layout\\nuint32[]          data          # array of data\\n\\n\\n================================================================================\\nMSG: std_msgs/MultiArrayLayout\\n# The multiarray declares a generic multi-dimensional array of a\\n# particular data type.  Dimensions are ordered from outer most\\n# to inner most.\\n\\nMultiArrayDimension[] dim # Array of dimension properties\\nuint32 data_offset        # padding elements at front of data\\n\\n# Accessors should ALWAYS be written in terms of dimension stride\\n# and specified outer-most dimension first.\\n# \\n# multiarray(i,j,k) = data[data_offset + dim_stride[1]*i + dim_stride[2]*j + k]\\n#\\n# A standard, 3-channel 640x480 image with interleaved color channels\\n# would be specified as:\\n#\\n# dim[0].label  = \"height\"\\n# dim[0].size   = 480\\n# dim[0].stride = 3*640*480 = 921600  (note dim[0] stride is just size of image)\\n# dim[1].label  = \"width\"\\n# dim[1].size   = 640\\n# dim[1].stride = 3*640 = 1920\\n# dim[2].label  = \"channel\"\\n# dim[2].size   = 3\\n# dim[2].stride = 3\\n#\\n# multiarray(i,j,k) refers to the ith row, jth column, and kth channel.\\n\\n================================================================================\\nMSG: std_msgs/MultiArrayDimension\\nstring label   # label of given dimension\\nuint32 size    # size of given dimension (in type units)\\nuint32 stride  # stride of given dimension', 'callerid': '/ros_cle_simulation_31594_1516976831299', 'tcp_nodelay': '0', 'md5sum': '4d6a180abc9be191b96a7eda6c8a233d', 'topic': '/thimblerigger_solver/grid_activations', 'type': 'std_msgs/UInt32MultiArray'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARN] [1516977327.451029, 186.601000]: Could not process inbound connection: [/virtual_coach] is not a publisher of [/thimblerigger_solver/grid_activations]. Topics are [['/robot/neck_pitch/pos', 'std_msgs/Float64'], ['/robot/r_elbow/pos', 'std_msgs/Float64'], ['/rosout', 'rosgraph_msgs/Log'], ['/robot/l_elbow/pos', 'std_msgs/Float64']]{'message_definition': '# Please look at the MultiArrayLayout message definition for\\n# documentation on all multiarrays.\\n\\nMultiArrayLayout  layout        # specification of data layout\\nuint32[]          data          # array of data\\n\\n\\n================================================================================\\nMSG: std_msgs/MultiArrayLayout\\n# The multiarray declares a generic multi-dimensional array of a\\n# particular data type.  Dimensions are ordered from outer most\\n# to inner most.\\n\\nMultiArrayDimension[] dim # Array of dimension properties\\nuint32 data_offset        # padding elements at front of data\\n\\n# Accessors should ALWAYS be written in terms of dimension stride\\n# and specified outer-most dimension first.\\n# \\n# multiarray(i,j,k) = data[data_offset + dim_stride[1]*i + dim_stride[2]*j + k]\\n#\\n# A standard, 3-channel 640x480 image with interleaved color channels\\n# would be specified as:\\n#\\n# dim[0].label  = \"height\"\\n# dim[0].size   = 480\\n# dim[0].stride = 3*640*480 = 921600  (note dim[0] stride is just size of image)\\n# dim[1].label  = \"width\"\\n# dim[1].size   = 640\\n# dim[1].stride = 3*640 = 1920\\n# dim[2].label  = \"channel\"\\n# dim[2].size   = 3\\n# dim[2].stride = 3\\n#\\n# multiarray(i,j,k) refers to the ith row, jth column, and kth channel.\\n\\n================================================================================\\nMSG: std_msgs/MultiArrayDimension\\nstring label   # label of given dimension\\nuint32 size    # size of given dimension (in type units)\\nuint32 stride  # stride of given dimension', 'callerid': '/ros_cle_simulation_31594_1516976831299', 'tcp_nodelay': '0', 'md5sum': '4d6a180abc9be191b96a7eda6c8a233d', 'topic': '/thimblerigger_solver/grid_activations', 'type': 'std_msgs/UInt32MultiArray'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "destroying the solver...\n",
      "WARNING: [2018-01-26 15:35:29,452 - rosout] Could not process inbound connection: [/virtual_coach] is not a publisher of [/thimblerigger_solver/grid_activations]. Topics are [['/robot/neck_pitch/pos', 'std_msgs/Float64'], ['/robot/r_elbow/pos', 'std_msgs/Float64'], ['/rosout', 'rosgraph_msgs/Log'], ['/robot/l_elbow/pos', 'std_msgs/Float64']]{'message_definition': '# Please look at the MultiArrayLayout message definition for\\n# documentation on all multiarrays.\\n\\nMultiArrayLayout  layout        # specification of data layout\\nuint32[]          data          # array of data\\n\\n\\n================================================================================\\nMSG: std_msgs/MultiArrayLayout\\n# The multiarray declares a generic multi-dimensional array of a\\n# particular data type.  Dimensions are ordered from outer most\\n# to inner most.\\n\\nMultiArrayDimension[] dim # Array of dimension properties\\nuint32 data_offset        # padding elements at front of data\\n\\n# Accessors should ALWAYS be written in terms of dimension stride\\n# and specified outer-most dimension first.\\n# \\n# multiarray(i,j,k) = data[data_offset + dim_stride[1]*i + dim_stride[2]*j + k]\\n#\\n# A standard, 3-channel 640x480 image with interleaved color channels\\n# would be specified as:\\n#\\n# dim[0].label  = \"height\"\\n# dim[0].size   = 480\\n# dim[0].stride = 3*640*480 = 921600  (note dim[0] stride is just size of image)\\n# dim[1].label  = \"width\"\\n# dim[1].size   = 640\\n# dim[1].stride = 3*640 = 1920\\n# dim[2].label  = \"channel\"\\n# dim[2].size   = 3\\n# dim[2].stride = 3\\n#\\n# multiarray(i,j,k) refers to the ith row, jth column, and kth channel.\\n\\n================================================================================\\nMSG: std_msgs/MultiArrayDimension\\nstring label   # label of given dimension\\nuint32 size    # size of given dimension (in type units)\\nuint32 stride  # stride of given dimension', 'callerid': '/ros_cle_simulation_31594_1516976831299', 'tcp_nodelay': '0', 'md5sum': '4d6a180abc9be191b96a7eda6c8a233d', 'topic': '/thimblerigger_solver/grid_activations', 'type': 'std_msgs/UInt32MultiArray'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARN] [1516977329.452518, 186.601000]: Could not process inbound connection: [/virtual_coach] is not a publisher of [/thimblerigger_solver/grid_activations]. Topics are [['/robot/neck_pitch/pos', 'std_msgs/Float64'], ['/robot/r_elbow/pos', 'std_msgs/Float64'], ['/rosout', 'rosgraph_msgs/Log'], ['/robot/l_elbow/pos', 'std_msgs/Float64']]{'message_definition': '# Please look at the MultiArrayLayout message definition for\\n# documentation on all multiarrays.\\n\\nMultiArrayLayout  layout        # specification of data layout\\nuint32[]          data          # array of data\\n\\n\\n================================================================================\\nMSG: std_msgs/MultiArrayLayout\\n# The multiarray declares a generic multi-dimensional array of a\\n# particular data type.  Dimensions are ordered from outer most\\n# to inner most.\\n\\nMultiArrayDimension[] dim # Array of dimension properties\\nuint32 data_offset        # padding elements at front of data\\n\\n# Accessors should ALWAYS be written in terms of dimension stride\\n# and specified outer-most dimension first.\\n# \\n# multiarray(i,j,k) = data[data_offset + dim_stride[1]*i + dim_stride[2]*j + k]\\n#\\n# A standard, 3-channel 640x480 image with interleaved color channels\\n# would be specified as:\\n#\\n# dim[0].label  = \"height\"\\n# dim[0].size   = 480\\n# dim[0].stride = 3*640*480 = 921600  (note dim[0] stride is just size of image)\\n# dim[1].label  = \"width\"\\n# dim[1].size   = 640\\n# dim[1].stride = 3*640 = 1920\\n# dim[2].label  = \"channel\"\\n# dim[2].size   = 3\\n# dim[2].stride = 3\\n#\\n# multiarray(i,j,k) refers to the ith row, jth column, and kth channel.\\n\\n================================================================================\\nMSG: std_msgs/MultiArrayDimension\\nstring label   # label of given dimension\\nuint32 size    # size of given dimension (in type units)\\nuint32 stride  # stride of given dimension', 'callerid': '/ros_cle_simulation_31594_1516976831299', 'tcp_nodelay': '0', 'md5sum': '4d6a180abc9be191b96a7eda6c8a233d', 'topic': '/thimblerigger_solver/grid_activations', 'type': 'std_msgs/UInt32MultiArray'}\n"
     ]
    }
   ],
   "source": [
    "with solver:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Time  real  estimate\n",
      "0      15.20     1         0\n",
      "1      15.22     1         0\n",
      "2      15.24     1         0\n",
      "3      15.26     1         0\n",
      "4      15.28     1         0\n",
      "5      15.30     1         0\n",
      "6      15.32     1         0\n",
      "7      15.34     1         0\n",
      "8      15.36     1         0\n",
      "9      15.38     1         0\n",
      "10     15.40     1         0\n",
      "11     15.42     1         0\n",
      "12     15.44     1         0\n",
      "13     15.46     1         0\n",
      "14     15.48     1         0\n",
      "15     15.50     1         0\n",
      "16     15.52     1         0\n",
      "17     15.54     1         0\n",
      "18     15.56     1         0\n",
      "19     15.58     1         0\n",
      "20     15.60     1         0\n",
      "21     15.62     1         0\n",
      "22     15.64     1         0\n",
      "23     15.66     1         0\n",
      "24     15.68     1         0\n",
      "25     15.70     1         0\n",
      "26     15.72     1         0\n",
      "27     15.74     1         0\n",
      "28     15.76     1         0\n",
      "29     15.78     1         0\n",
      "...      ...   ...       ...\n",
      "8339  181.98     1         0\n",
      "8340  182.00     1         0\n",
      "8341  182.02     1         0\n",
      "8342  182.04     1         0\n",
      "8343  182.06     1         0\n",
      "8344  182.08     1         0\n",
      "8345  182.10     1         0\n",
      "8346  182.12     1         0\n",
      "8347  182.14     1         0\n",
      "8348  182.16     1         0\n",
      "8349  182.18     1         0\n",
      "8350  182.20     1         0\n",
      "8351  182.22     1         0\n",
      "8352  182.24     1         0\n",
      "8353  182.26     1         0\n",
      "8354  182.28     1         0\n",
      "8355  182.30     1         0\n",
      "8356  182.32     1         0\n",
      "8357  182.34     1         0\n",
      "8358  182.36     1         0\n",
      "8359  182.38     1         0\n",
      "8360  182.40     1         0\n",
      "8361  182.42     1         0\n",
      "8362  182.44     1         0\n",
      "8363  182.46     1         0\n",
      "8364  182.48     1         0\n",
      "8365  182.50     1         0\n",
      "8366  182.52     1         0\n",
      "8367  182.54     1         0\n",
      "8368  182.56     1         0\n",
      "\n",
      "[8369 rows x 3 columns]\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "csv_file = os.path.join(tmp_folder, \"index_real_estimate.csv\")\n",
    "data_frame = pandas.read_csv(csv_file)\n",
    "score = np.sum(data_frame[\"real\"]==data_frame[\"estimate\"])\n",
    "print(data_frame)\n",
    "print(score)\n",
    "print(score / len(data_frame[\"real\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
