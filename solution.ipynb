{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the thimblerigger\n",
    "\n",
    "First of all, lets disable logging from the virtual coach created here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable global logging from the virtual coach\n",
    "import logging\n",
    "logging.disable(logging.INFO)\n",
    "logging.getLogger('rospy').propagate = False\n",
    "logging.getLogger('rosout').propagate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, I optain a VirtualCoach object as an entry point to the NRP platform.\n",
    "Since I'm working on a local install, we will see a warning message telling us that we have not provided a user name.\n",
    "This is fine for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log into the virtual coach, update with your credentials\n",
    "try:\n",
    "    from hbp_nrp_virtual_coach.virtual_coach import VirtualCoach\n",
    "    vc = VirtualCoach(environment='local')\n",
    "except ImportError as e:\n",
    "    print(e)\n",
    "    print(\"You have to start this notebook with the command:\\\n",
    "          cle-virtual-coach jupyter notebook\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I just cluster all imports needed in one global cell so I know where everything is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import math\n",
    "from thread import start_new_thread\n",
    "\n",
    "import cv2\n",
    "import rospy\n",
    "import numpy as np\n",
    "from cv_bridge import CvBridge\n",
    "import hbp_nrp_cle.tf_framework as nrp\n",
    "\n",
    "from gazebo_msgs.msg import ModelState\n",
    "from std_srvs.srv import Trigger, TriggerResponse\n",
    "from gazebo_msgs.srv import GetModelState, SetModelState\n",
    "from std_msgs.msg import UInt32MultiArray, MultiArrayDimension, Float64\n",
    "\n",
    "import thimblerigger_config as tc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving the robot around the simulation\n",
    "\n",
    "I need to move the robot around the simulation to find a spot where it has a good view\n",
    "over the whole challenge setup. Since there may be multiple ways to move around, I define the RobotMover interface,\n",
    "which does nothing by itself, but has methods to move a model through the simulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobotMover(object):\n",
    "    \"\"\"\n",
    "    Interface to move an object through the simulation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name=\"robot\"):\n",
    "        \"\"\"\n",
    "        param model_name: The name in the gazebo simulation of the object that should move.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def go_to_pose(self, x, y, orientation):\n",
    "        \"\"\"\n",
    "        Moves the object to the given coordinates.\n",
    "        \n",
    "        param x: x coordinate to go to.\n",
    "        param y: y coordinate to go to.\n",
    "        param orientation: Quaternion orientation vector.\n",
    "        \"\"\"\n",
    "        raise NotImplemented(\"Please use a subtype of the RobotMover!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is the perception challenge, I will assume that it is ok to just teleport through the \n",
    "simulation. Thus, I build a TeleportRobotMover, which inherits from the RobotMover interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeleportRobotMover(RobotMover):\n",
    "\n",
    "    def __init__(self, model_name=\"robot\"):\n",
    "        \"\"\"\n",
    "        param model_name: The name in the gazebo simulation of the object that should be teleported.\n",
    "        \"\"\"\n",
    "        self.get_position = rospy.ServiceProxy(\"/gazebo/get_model_state\", GetModelState)\n",
    "        self.set_position = rospy.ServiceProxy(\"/gazebo/set_model_state\", SetModelState)\n",
    "        super(TeleportRobotMover, self).__init__(model_name=model_name)\n",
    "\n",
    "    def go_to_pose(self, x, y, orientation):\n",
    "        \"\"\"\n",
    "        Teleports the object to the given coordinates.\n",
    "        \n",
    "        param x: x coordinate (world coordinates) to go to.\n",
    "        param y: y coordinate (world coordinates) to go to.\n",
    "        param orientation: Quaternion orientation vector.\n",
    "        \"\"\"\n",
    "        # Obtain the current pose information, because I do not want\n",
    "        # to change scale, twist, z-coordinate etc.\n",
    "        current_robot_pose = self.get_position(self.model_name, \"\")\n",
    "        new_state = ModelState()\n",
    "        new_state.model_name = self.model_name\n",
    "        new_state.pose = current_robot_pose.pose\n",
    "        new_state.scale = current_robot_pose.scale\n",
    "        new_state.twist = current_robot_pose.twist\n",
    "        new_state.pose.position.x = x\n",
    "        new_state.pose.position.y = y\n",
    "        new_state.pose.orientation.x = orientation[1]\n",
    "        new_state.pose.orientation.y = orientation[2]\n",
    "        new_state.pose.orientation.z = orientation[3]\n",
    "        new_state.pose.orientation.w = orientation[0]\n",
    "        new_state.reference_frame = \"world\"\n",
    "        self.set_position(new_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with the challenge interface\n",
    "\n",
    "I also need a convenient way to interact with the services provided by the thimblerigger challenge. \n",
    "I simply store handles to the ServiceProxies in a wrapper object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChallengeInteractor(object):\n",
    "\n",
    "    \"\"\"\n",
    "    Interface to interact with the thimblerigger challenge.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Accquire persistent handles to all relevant services\n",
    "        print(\"Waiting for show mug service...\")\n",
    "        rospy.wait_for_service(tc.thimblerigger_show_correct_service, 10)\n",
    "        print(\"Show mug service available.\")\n",
    "        \n",
    "        print(\"Waiting for hide mug service...\")\n",
    "        rospy.wait_for_service(tc.thimblerigger_hide_correct_service, 10)\n",
    "        print(\"Hide mug service available.\")\n",
    "        \n",
    "        print(\"Waiting for shuffle service...\")\n",
    "        rospy.wait_for_service(tc.thimblerigger_shuffle_service, 10)\n",
    "        print(\"Shuffle service available.\")\n",
    "        \n",
    "        print(\"Waiting for reset service...\")\n",
    "        rospy.wait_for_service(tc.thimblerigger_reset_service, 10)\n",
    "        print(\"Reset service available.\")\n",
    "        \n",
    "        print(\"All thimblerigger services found.\")                       \n",
    "        self.show_correct_mug = rospy.ServiceProxy(tc.thimblerigger_show_correct_service, Trigger)\n",
    "        self.hide_correct_mug = rospy.ServiceProxy(tc.thimblerigger_hide_correct_service, Trigger)\n",
    "        self.shuffle = rospy.ServiceProxy(tc.thimblerigger_shuffle_service, Trigger)\n",
    "        self.reset = rospy.ServiceProxy(tc.thimblerigger_reset_service, Trigger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the puzzle\n",
    "\n",
    "Let's create a solver, which actually beats the challenge. For this, we need two transfer functions.\n",
    "One to visualize what the robot is predicting, and one to make the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_centers = \"\"\"\n",
    "@nrp.MapRobotSubscriber(\"img_msg\", Topic(\"/icub_model/left_eye_camera/image_raw\", sensor_msgs.msg.Image))\n",
    "@nrp.MapVariable(\"var_center_points\", initial_value=[None, None], scope=nrp.GLOBAL)\n",
    "@nrp.MapVariable(\"var_estimate\", initial_value=None, scope=nrp.GLOBAL)\n",
    "@nrp.Robot2Neuron()\n",
    "def extract_centers(t, img_msg, var_center_points, var_estimate):\n",
    "\n",
    "    if img_msg.value is None:\n",
    "        return\n",
    "        \n",
    "    img = CvBridge().imgmsg_to_cv2(img_msg.value, \"bgr8\")\n",
    "    most_vibrant_channel = np.argmax(img, axis=2)\n",
    "    \n",
    "    # Filter red \n",
    "    img[most_vibrant_channel != 2] = 0\n",
    "    img[img[:,:,2] < 150] = 0\n",
    "    red = img[:, :, 2]\n",
    "    _, thresh = cv2.threshold(red, 150, 255, 0)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    thresh = cv2.erode(thresh, kernel,iterations = 1)\n",
    "    im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    contour_thresh = 50\n",
    "    contours = [c for c in contours if cv2.contourArea(c) > contour_thresh]\n",
    "\n",
    "    moments = [cv2.moments(c) for c in contours]\n",
    "    centers = sorted([(int(M['m10']/M['m00']), int(M['m01']/M['m00'])) for M in moments])\n",
    "    center_points = np.array(centers)\n",
    "    \n",
    "    if center_points.shape != (3, 2):\n",
    "        return    \n",
    "        \n",
    "    var_center_points.value[0], var_center_points.value[1] = center_points, var_center_points.value[0]\n",
    "    \n",
    "    estimate = var_estimate.value\n",
    "    \n",
    "    if estimate is not None and var_center_points.value != [None, None]:\n",
    "        current_centers, old_centers = var_center_points.value\n",
    "        diff = np.linalg.norm(current_centers-old_centers[estimate], axis=-1)\n",
    "        var_estimate.value = np.argmin(diff)\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = \"\"\"\n",
    "\n",
    "@nrp.MapSpikeSource(\"prediction\", nrp.map_neurons(range(0, 3), lambda i: nrp.brain.prediction[i]), nrp.fixed_frequency)\n",
    "@nrp.MapVariable(\"var_estimate\", initial_value=None, scope=nrp.GLOBAL)\n",
    "@nrp.Robot2Neuron()\n",
    "def predict(t, var_estimate, prediction):\n",
    "    if var_estimate.value is not None:\n",
    "        new_rates = [0.] * 3\n",
    "        new_rates[var_estimate.value] = 100.\n",
    "        prediction.rate = new_rates\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_green = \"\"\"\n",
    "import numpy as np\n",
    "\n",
    "@nrp.MapRobotSubscriber(\"img_msg\", Topic(\"/icub_model/left_eye_camera/image_raw\", sensor_msgs.msg.Image))\n",
    "@nrp.MapSpikeSource(\"green_neurons\", nrp.map_neurons(range(0, 3), lambda i: nrp.brain.greens[i]), nrp.dc_source)\n",
    "@nrp.Robot2Neuron()\n",
    "def track_green(t, img_msg, green_neurons):\n",
    "\n",
    "    if img_msg.value is None:\n",
    "        return\n",
    "    \n",
    "    img = CvBridge().imgmsg_to_cv2(img_msg.value, \"bgr8\")\n",
    "    green_channel = np.squeeze(img[:, :, 1])\n",
    "    green_channel = green_channel[120:160, 85:245]\n",
    "    \n",
    "    m1 = np.mean(green_channel[:, 0:53])\n",
    "    m2 = np.mean(green_channel[:, 53: 106])\n",
    "    m3 = np.mean(green_channel[:, 106:])\n",
    "    mean_green = np.array([m1, m2, m3])\n",
    "    mean_green[mean_green < 80.] = 0.\n",
    "    green_neurons.amplitude = mean_green\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_initial_track = \"\"\"\n",
    "\n",
    "@nrp.MapVariable(\"var_estimate\", initial_value=None, scope=nrp.GLOBAL)\n",
    "@nrp.MapSpikeSink(\"green_neurons\", nrp.map_neurons(range(0, 3), lambda i: nrp.brain.greens[i]), nrp.leaky_integrator_alpha)\n",
    "@nrp.Neuron2Robot()\n",
    "def find_initial_track(t, var_estimate, green_neurons):\n",
    "\n",
    "    if var_estimate.value is not None:\n",
    "        return\n",
    "\n",
    "    volt = green_neurons.voltage\n",
    "    one_lifted = np.any(volt > 1.)\n",
    "    if one_lifted:\n",
    "        correct_id = np.argmax(volt)\n",
    "        var_estimate.value = correct_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    Solver for the thimblerigger challenge.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tfs_to_add, shutdown=False):\n",
    "        \"\"\"\n",
    "        param predict_tf: Transfer function that predicts which mug contains the ball.\n",
    "        param visualize_tf: Transfer function that visualizes the predictions made by predict_tf.\n",
    "        param shutdown: Shut down the simulation on context exit. Otherwise pause.\n",
    "        \"\"\"\n",
    "        self.sim = vc.launch_experiment('ExDPerceptionChallengeKIT')\n",
    "        self.tfs = tfs_to_add\n",
    "        \n",
    "        self.shutdown = shutdown\n",
    "        \n",
    "        self.solved = False\n",
    "        self.current_view = \"front\"\n",
    "        self.robot_mover = None \n",
    "        self.challenge = None \n",
    "\n",
    "\n",
    "    def set_joints_start(self):\n",
    "        \"\"\"\n",
    "        Moves the robot to a position from which it can overview the challenge setup.\n",
    "        \"\"\"\n",
    "        neck = rospy.Publisher(\"/robot/neck_pitch/pos\", Float64, queue_size=1)\n",
    "        l_elbow = rospy.Publisher(\"/robot/l_elbow/pos\", Float64, queue_size=1)\n",
    "        r_elbow = rospy.Publisher(\"/robot/r_elbow/pos\", Float64, queue_size=1)\n",
    "        \n",
    "        def lower_gaze_and_arms():\n",
    "            while not rospy.is_shutdown():\n",
    "                neck.publish(Float64(-0.8))\n",
    "                l_elbow.publish(Float64(-25.0))\n",
    "                r_elbow.publish(Float64(-25.0))\n",
    "            l_elbow.unregister()\n",
    "            r_elbow.unregister()\n",
    "            \n",
    "        start_new_thread(lower_gaze_and_arms, ())\n",
    "        # The sleeps are necessary to stop the robot from tumbling over\n",
    "        # because it teleports and moves at the same time.\n",
    "        time.sleep(3)\n",
    "        self.side_look()\n",
    "        time.sleep(3)\n",
    "        print(\"Moved robot to start pose\")\n",
    "        \n",
    "    def __enter__(self):\n",
    "        \"\"\"\n",
    "        Start the simulation and move the robot to the starting pose.\n",
    "        Also accquire handles to interact with the challenge.\n",
    "        \"\"\"\n",
    "        self.sim.start()\n",
    "        self.robot_mover = TeleportRobotMover()\n",
    "        self.challenge = ChallengeInteractor()\n",
    "        self.set_joints_start()\n",
    "        # Robot should be in start pose now\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        \"\"\"\n",
    "        Pause the execution of the simulation so the results can be viewed.\n",
    "        \"\"\"\n",
    "        if self.shutdown or exc_type is not None:\n",
    "            print(\"Shutting the simulation down...\")\n",
    "            self.sim.stop()\n",
    "        else:\n",
    "            print(\"Pausing the simulation...\")\n",
    "            self.sim.pause()\n",
    "        \n",
    "        return False\n",
    "            \n",
    "\n",
    "    def front_look(self):\n",
    "        \"\"\"\n",
    "        Moves the robot to the challenge defined start position.\n",
    "        \"\"\"\n",
    "        self.robot_mover.go_to_pose(x=-0.75, y=0., orientation=(0, 0, 1, 0))\n",
    "        self.current_view = \"front\"\n",
    "\n",
    "\n",
    "    def side_look(self):\n",
    "        \"\"\"\n",
    "        Moves the robot to the custom start position.\n",
    "        \"\"\"\n",
    "        orientation = (math.sqrt(0.5), 0, 0, -math.sqrt(0.5))\n",
    "        self.robot_mover.go_to_pose(x=0.4, y=-0.9, orientation=orientation)\n",
    "        self.current_view = \"side\"\n",
    "        \n",
    "    def solve(self, interactive=True):\n",
    "        \"\"\"\n",
    "        Solves the currently started challenge.\n",
    "        \n",
    "        param interactive: Wait for user input between all steps.\n",
    "        \"\"\"\n",
    "        def maybe_get_input(phrase=\"continue\"):\n",
    "            if interactive:\n",
    "                raw_input(\"Insert 'Enter' to {}.\".format(phrase))\n",
    "                \n",
    "        if self.solved:\n",
    "            maybe_get_input(\"reset the simulation\")\n",
    "            self.sim.start()\n",
    "            \n",
    "            # TODO check how this works\n",
    "            @nrp.MapVariable(\"estimate\", initial_value=None, scope=nrp.GLOBAL)\n",
    "            def reset_estimate(estimate):\n",
    "                estimate.value = None\n",
    "            \n",
    "            reset_estimate()\n",
    "            self.challenge.reset()\n",
    "            \n",
    "        \n",
    "        for tf_code in self.tfs.values():\n",
    "            self.sim.add_transfer_function(tf_code)\n",
    "      \n",
    "        time.sleep(2)  # Wait for the TFs to be registered\n",
    "            \n",
    "        maybe_get_input(phrase=\"show the correct mug\")        \n",
    "        self.challenge.show_correct_mug()\n",
    "        maybe_get_input(phrase=\"hide the correct mug\")\n",
    "        self.challenge.hide_correct_mug()\n",
    "        maybe_get_input(phrase=\"shuffle the mugs\")\n",
    "        self.challenge.shuffle()\n",
    "        maybe_get_input(phrase=\"show to correct mug\")\n",
    "        self.challenge.show_correct_mug()   \n",
    "        self.solved = True\n",
    "                \n",
    "        for tf_name in self.tfs.keys():\n",
    "            self.sim.delete_transfer_function(tf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the solver\n",
    "\n",
    "Now we simply need to create the solver object within its context.\n",
    "I recommend watching the frontend in a separate window.\n",
    "The experiment will pause itself. You can run the solve method multiple times.\n",
    "Please note that in some cases shuffling the mugs will appear to not work, as a random permutation is chosen.\n",
    "In some cases, that permutation is the one the mugs are already in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-3b162c1c28b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Pass interactive=False to just run everything at once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-202-9636aead786c>\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, interactive)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Wait for the TFs to be registered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mmaybe_get_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"show the correct mug\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchallenge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_correct_mug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mmaybe_get_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"hide the correct mug\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-202-9636aead786c>\u001b[0m in \u001b[0;36mmaybe_get_input\u001b[0;34m(phrase)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mmaybe_get_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"continue\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mraw_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Insert 'Enter' to {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolved\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hbp/.local/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         )\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hbp/.local/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test = {\"extract_centers\": extract_centers,\n",
    "        \"track_green\": track_green,\n",
    "        \"find_initial_track\": find_initial_track,\n",
    "        \"predict\": predict}\n",
    "with Solver(tfs_to_add=test,\n",
    "            shutdown=False) as solver:\n",
    "    \n",
    "    # Pass interactive=False to just run everything at once.\n",
    "    solver.solve(interactive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
