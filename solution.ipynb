{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the thimblerigger\n",
    "\n",
    "First of all, lets disable logging from the virtual coach created here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable global logging from the virtual coach\n",
    "import logging\n",
    "logging.disable(logging.INFO)\n",
    "logging.getLogger('rospy').propagate = False\n",
    "logging.getLogger('rosout').propagate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, I optain a VirtualCoach object as an entry point to the NRP platform.\n",
    "Since I'm working on a local install, we will see a warning message telling us that we have not provided a user name.\n",
    "This is fine for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log into the virtual coach, update with your credentials\n",
    "try:\n",
    "    from hbp_nrp_virtual_coach.virtual_coach import VirtualCoach\n",
    "    vc = VirtualCoach(environment='local')\n",
    "except ImportError as e:\n",
    "    print(e)\n",
    "    print(\"You have to start this notebook with the command:\\\n",
    "          cle-virtual-coach jupyter notebook\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I just cluster all imports needed in one global cell so I know where everything is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import math\n",
    "from thread import start_new_thread\n",
    "\n",
    "import cv2\n",
    "import rospy\n",
    "import numpy as np\n",
    "from cv_bridge import CvBridge\n",
    "import hbp_nrp_cle.tf_framework as nrp\n",
    "\n",
    "from gazebo_msgs.msg import ModelState\n",
    "from std_srvs.srv import Trigger, TriggerResponse\n",
    "from gazebo_msgs.srv import GetModelState, SetModelState\n",
    "from std_msgs.msg import UInt32MultiArray, MultiArrayDimension, Float64\n",
    "\n",
    "import thimblerigger_config as tc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving the robot around the simulation\n",
    "\n",
    "I need to move the robot around the simulation to find a spot where it has a good view\n",
    "over the whole challenge setup. Since there may be multiple ways to move around, I define the RobotMover interface,\n",
    "which does nothing by itself, but has methods to move a model through the simulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobotMover(object):\n",
    "    \"\"\"\n",
    "    Interface to move an object through the simulation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name=\"robot\"):\n",
    "        \"\"\"\n",
    "        param model_name: The name in the gazebo simulation of the object that should move.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def go_to_pose(self, x, y, orientation):\n",
    "        \"\"\"\n",
    "        Moves the object to the given coordinates.\n",
    "        \n",
    "        param x: x coordinate to go to.\n",
    "        param y: y coordinate to go to.\n",
    "        param orientation: Quaternion orientation vector.\n",
    "        \"\"\"\n",
    "        raise NotImplemented(\"Please use a subtype of the RobotMover!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is the perception challenge, I will assume that it is ok to just teleport through the \n",
    "simulation. Thus, I build a TeleportRobotMover, which inherits from the RobotMover interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeleportRobotMover(RobotMover):\n",
    "\n",
    "    def __init__(self, model_name=\"robot\"):\n",
    "        \"\"\"\n",
    "        param model_name: The name in the gazebo simulation of the object that should be teleported.\n",
    "        \"\"\"\n",
    "        self.get_position = rospy.ServiceProxy(\"/gazebo/get_model_state\", GetModelState)\n",
    "        self.set_position = rospy.ServiceProxy(\"/gazebo/set_model_state\", SetModelState)\n",
    "        super(TeleportRobotMover, self).__init__(model_name=model_name)\n",
    "\n",
    "    def go_to_pose(self, x, y, orientation):\n",
    "        \"\"\"\n",
    "        Teleports the object to the given coordinates.\n",
    "        \n",
    "        param x: x coordinate (world coordinates) to go to.\n",
    "        param y: y coordinate (world coordinates) to go to.\n",
    "        param orientation: Quaternion orientation vector.\n",
    "        \"\"\"\n",
    "        # Obtain the current pose information, because I do not want\n",
    "        # to change scale, twist, z-coordinate etc.\n",
    "        current_robot_pose = self.get_position(self.model_name, \"\")\n",
    "        new_state = ModelState()\n",
    "        new_state.model_name = self.model_name\n",
    "        new_state.pose = current_robot_pose.pose\n",
    "        new_state.scale = current_robot_pose.scale\n",
    "        new_state.twist = current_robot_pose.twist\n",
    "        new_state.pose.position.x = x\n",
    "        new_state.pose.position.y = y\n",
    "        new_state.pose.orientation.x = orientation[1]\n",
    "        new_state.pose.orientation.y = orientation[2]\n",
    "        new_state.pose.orientation.z = orientation[3]\n",
    "        new_state.pose.orientation.w = orientation[0]\n",
    "        new_state.reference_frame = \"world\"\n",
    "        self.set_position(new_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with the challenge interface\n",
    "\n",
    "I also need a convenient way to interact with the services provided by the thimblerigger challenge. \n",
    "I simply store handles to the ServiceProxies in a wrapper object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChallengeInteractor(object):\n",
    "\n",
    "    \"\"\"\n",
    "    Interface to interact with the thimblerigger challenge.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Accquire persistent handles to all relevant services\n",
    "        print(\"Waiting for show mug service...\")\n",
    "        rospy.wait_for_service(tc.thimblerigger_show_correct_service, 10)\n",
    "        print(\"Show mug service available.\")\n",
    "        \n",
    "        print(\"Waiting for hide mug service...\")\n",
    "        rospy.wait_for_service(tc.thimblerigger_hide_correct_service, 10)\n",
    "        print(\"Hide mug service available.\")\n",
    "        \n",
    "        print(\"Waiting for shuffle service...\")\n",
    "        rospy.wait_for_service(tc.thimblerigger_shuffle_service, 10)\n",
    "        print(\"Shuffle service available.\")\n",
    "        \n",
    "        print(\"Waiting for reset service...\")\n",
    "        rospy.wait_for_service(tc.thimblerigger_reset_service, 10)\n",
    "        print(\"Reset service available.\")\n",
    "        \n",
    "        print(\"All thimblerigger services found.\")                       \n",
    "        self.show_correct_mug = rospy.ServiceProxy(tc.thimblerigger_show_correct_service, Trigger)\n",
    "        self.hide_correct_mug = rospy.ServiceProxy(tc.thimblerigger_hide_correct_service, Trigger)\n",
    "        self.shuffle = rospy.ServiceProxy(tc.thimblerigger_shuffle_service, Trigger)\n",
    "        self.reset = rospy.ServiceProxy(tc.thimblerigger_reset_service, Trigger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the puzzle\n",
    "\n",
    "Let's create a solver, which actually beats the challenge. For this, we need two transfer functions.\n",
    "One to visualize what the robot is predicting, and one to make the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronal_extract_centers = \"\"\"\n",
    "@nrp.MapRobotSubscriber(\"img_msg\", Topic(\"/icub_model/left_eye_camera/image_raw\", sensor_msgs.msg.Image))\n",
    "@nrp.MapSpikeSource(\"retina\",  nrp.map_neurons(range(0, 1200), lambda i: nrp.brain.retina[i]), nrp.fixed_frequency)\n",
    "@nrp.Neuron2Robot(Topic(\"/robot/red\", sensor_msgs.msg.Image))\n",
    "def neuronal_extract_centers(t, img_msg, retina):\n",
    "    if img_msg.value is None:\n",
    "        return img_msg\n",
    "        \n",
    "    img = CvBridge().imgmsg_to_cv2(img_msg.value, \"bgr8\")\n",
    "    most_vibrant_channel = np.argmax(img, axis=2)\n",
    "    \n",
    "    # Filter red \n",
    "    img[most_vibrant_channel != 2] = 0\n",
    "    img[img[:,:,2] < 150] = 0\n",
    "    red = img[:, :, 2]\n",
    "    _, thresh = cv2.threshold(red, 150, 255, 0)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    thresh = cv2.erode(thresh, kernel,iterations = 1)\n",
    "    #red[thresh != 255] = 0\n",
    "    thresh = cv2.resize(thresh, (40, 30))\n",
    "    retina.rate = thresh.flatten()\n",
    "        \n",
    "    return CvBridge().cv2_to_imgmsg(np.array(retina.rate).reshape(thresh.shape).astype(np.uint8), encoding=\"mono8\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_retina = \"\"\"\n",
    "@nrp.MapSpikeSink(\"retina\",  nrp.map_neurons(range(0, 1200), lambda i: nrp.brain.retina[i]), nrp.population_rate)\n",
    "@nrp.MapVariable(\"var_center_points\", initial_value=None, scope=nrp.GLOBAL)\n",
    "@nrp.MapVariable(\"var_estimate\", initial_value=None, scope=nrp.GLOBAL)\n",
    "@nrp.Neuron2Robot(Topic(\"/robot/centers\", sensor_msgs.msg.Image))\n",
    "def read_retina(t, retina, var_center_points, var_estimate):\n",
    "    \n",
    "    num_mugs = 3\n",
    "    rates = np.array(retina.rate)\n",
    "    rates = rates.reshape((30, 40))\n",
    "    left = rates[:, 0:17]\n",
    "    middle = rates[:, 17:25]\n",
    "    right = rates[:, 25:40]\n",
    "    l_center = np.array(np.unravel_index(np.argmax(left), left.shape)) + [0, 0]\n",
    "    m_center = np.array(np.unravel_index(np.argmax(middle), middle.shape)) + [0, 17]\n",
    "    r_center = np.array(np.unravel_index(np.argmax(right), right.shape)) + [0, 25]\n",
    "    \n",
    "    #clientLogger.info(np.transpose(np.nonzero(rates)))\n",
    "    #clientLogger.info([left[l_center], middle[m_center], right[r_center]])\n",
    "    \n",
    "    centers = np.array([l_center, m_center, r_center])\n",
    "    clientLogger.info(centers)\n",
    "    \n",
    "    #indices = np.argpartition(rates, -num_mugs)[-num_mugs:]\n",
    "    #indices = indices[np.argsort(-rates[indices])]\n",
    "    #rows, cols = np.unravel_index(indices, (40, 30))\n",
    "    #sorted_centers = np.array([[cols[i], rows[i]] for i in np.lexsort((rows, cols))])\n",
    "\n",
    "    var_center_points.value = centers\n",
    "    \n",
    "    visual = np.zeros_like(rates)\n",
    "    visual[tuple(centers.T)] = 255\n",
    "    return CvBridge().cv2_to_imgmsg(visual.astype(np.uint8), encoding=\"mono8\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_centers = \"\"\"\n",
    "@nrp.MapRobotSubscriber(\"img_msg\", Topic(\"/icub_model/left_eye_camera/image_raw\", sensor_msgs.msg.Image))\n",
    "@nrp.MapVariable(\"var_center_points\", initial_value=[None, None], scope=nrp.GLOBAL)\n",
    "@nrp.MapVariable(\"var_estimate\", initial_value=None, scope=nrp.GLOBAL)\n",
    "@nrp.MapSpikeSource(\"xyt\", nrp.map_neurons(range(0, 3), lambda i: nrp.brain.xyt[i]), nrp.fixed_frequency)\n",
    "@nrp.MapSpikeSource(\"minxyt_1\",  nrp.brain.minxyt_1[0], nrp.fixed_frequency)\n",
    "@nrp.Robot2Neuron()\n",
    "def extract_centers(t, img_msg, var_center_points, var_estimate, minxyt_1, xyt):\n",
    "\n",
    "    if img_msg.value is None:\n",
    "        return\n",
    "        \n",
    "    img = CvBridge().imgmsg_to_cv2(img_msg.value, \"bgr8\")\n",
    "    most_vibrant_channel = np.argmax(img, axis=2)\n",
    "    \n",
    "    # Filter red \n",
    "    img[most_vibrant_channel != 2] = 0\n",
    "    img[img[:,:,2] < 150] = 0\n",
    "    red = img[:, :, 2]\n",
    "    _, thresh = cv2.threshold(red, 150, 255, 0)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    thresh = cv2.erode(thresh, kernel,iterations = 1)\n",
    "    im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    contour_thresh = 50\n",
    "    contours = [c for c in contours if cv2.contourArea(c) > contour_thresh]\n",
    "\n",
    "    moments = [cv2.moments(c) for c in contours]\n",
    "    centers = sorted([(int(M['m10']/M['m00']), int(M['m01']/M['m00'])) for M in moments])\n",
    "    center_points = np.array(centers)\n",
    "    \n",
    "    if center_points.shape != (3, 2):\n",
    "        return    \n",
    "        \n",
    "    var_center_points.value[0], var_center_points.value[1] = center_points, var_center_points.value[0]\n",
    "    \n",
    "    estimate = var_estimate.value\n",
    "    if estimate is not None:\n",
    "        minxyt_1.rate =  np.sum(var_center_points.value[1][estimate]) / 10.\n",
    "        xyt.rate = np.sum(var_center_points.value[0], axis=-1) / 10.\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_green = \"\"\"\n",
    "import numpy as np\n",
    "\n",
    "@nrp.MapVariable(\"var_estimate\", initial_value=None, scope=nrp.GLOBAL)\n",
    "@nrp.MapRobotSubscriber(\"img_msg\", Topic(\"/icub_model/left_eye_camera/image_raw\", sensor_msgs.msg.Image))\n",
    "@nrp.MapSpikeSource(\"green_neurons\", nrp.map_neurons(range(0, 3), lambda i: nrp.brain.greens[i]), nrp.dc_source)\n",
    "@nrp.Robot2Neuron()\n",
    "def track_green(t, var_estimate, img_msg, green_neurons):\n",
    "\n",
    "    if img_msg.value is None:\n",
    "        return\n",
    "    \n",
    "    img = CvBridge().imgmsg_to_cv2(img_msg.value, \"bgr8\")\n",
    "    green_channel = np.squeeze(img[:, :, 1])\n",
    "    green_channel = green_channel[120:160, 85:245]\n",
    "    \n",
    "    m1 = np.mean(green_channel[:, 0:53])\n",
    "    m2 = np.mean(green_channel[:, 53: 106])\n",
    "    m3 = np.mean(green_channel[:, 106:])\n",
    "    mean_green = np.array([m1, m2, m3])\n",
    "    mean_green[mean_green < 80.] = 0.\n",
    "    green_neurons.amplitude = mean_green\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_initial_track = \"\"\"\n",
    "\n",
    "@nrp.MapVariable(\"var_estimate\", initial_value=None, scope=nrp.GLOBAL)\n",
    "@nrp.MapVariable(\"var_center_points\", initial_value=None, scope=nrp.GLOBAL)\n",
    "@nrp.MapSpikeSink(\"green_neurons\", nrp.map_neurons(range(0, 3), lambda i: nrp.brain.greens[i]), nrp.leaky_integrator_alpha)\n",
    "@nrp.Neuron2Robot()\n",
    "def find_initial_track(t, var_estimate, green_neurons, var_center_points):\n",
    "\n",
    "    if var_center_points.value is None or var_estimate.value is not None:\n",
    "        return\n",
    "\n",
    "    volt = green_neurons.voltage\n",
    "    one_lifted = np.any(volt > 1.)\n",
    "    if one_lifted:\n",
    "        centers = var_center_points.value\n",
    "        correct_id = np.argmax(volt)\n",
    "        var_estimate.value = centers[correct_id]\n",
    "        clientLogger.info(\"Initial track: {}\".format(correct_id))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = \"\"\"\n",
    "\n",
    "@nrp.MapVariable(\"var_estimate\", initial_value=None, scope=nrp.GLOBAL)\n",
    "@nrp.MapVariable(\"var_center_points\", initial_value=[None, None], scope=nrp.GLOBAL)\n",
    "@nrp.Robot2Neuron()\n",
    "def predict(t, var_estimate, var_center_points):\n",
    "    \n",
    "    if var_estimate.value is None or var_center_points.value is None:\n",
    "        return\n",
    "        \n",
    "    center_points = var_center_points.value\n",
    "    last_estimate = var_estimate.value\n",
    "    # We now have the last position of the correct mug\n",
    "    center_diffs = np.linalg.norm(center_points - last_estimate, axis=-1)\n",
    "    correct_id = np.argmin(center_diffs)\n",
    "    var_estimate.value = center_points[correct_id]\n",
    "    clientLogger.info(\"Tracking {}\".format(correct_id))\n",
    "    clientLogger.info(center_points)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_norms = \"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sensor_msgs\n",
    "\n",
    "@nrp.MapVariable(\"var_center_points\", initial_value=[None, None], scope=nrp.GLOBAL)\n",
    "@nrp.MapVariable(\"var_estimate\", initial_value=None, scope=nrp.GLOBAL)\n",
    "@nrp.MapSpikeSink(\"sums\", nrp.map_neurons(range(0, 3), lambda i: nrp.brain.sxt[i]), nrp.leaky_integrator_exp)\n",
    "@nrp.Robot2Neuron()\n",
    "def compute_norms(t, var_estimate, var_center_points, sums):\n",
    "    \n",
    "    center_points = var_center_points.value\n",
    "    estimate = var_estimate.value\n",
    "    \n",
    "    if center_points == [None, None] or estimate is None:\n",
    "        # Exit if we don't know yet where the ball is\n",
    "        return\n",
    "            \n",
    "    current_centers, old_centers = center_points\n",
    "    #clientLogger.info(\"sums: {}\".format(sums.voltage))\n",
    "    \n",
    "    if old_centers is not None:\n",
    "        cartesian = np.transpose([np.tile(sums.voltage, len(sums.voltage)), np.repeat(sums.voltage, len(sums.voltage))])\n",
    "        if not np.allclose(cartesian[0], cartesian[1], atol=1.):\n",
    "            var_estimate.value = np.argmin(sums.voltage)\n",
    "            clientLogger.info(\"Tracking: {} vs old {}\".format(var_estimate.value, estimate))   \n",
    "  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    Solver for the thimblerigger challenge.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tfs_to_add, shutdown=False):\n",
    "        \"\"\"\n",
    "        param predict_tf: Transfer function that predicts which mug contains the ball.\n",
    "        param visualize_tf: Transfer function that visualizes the predictions made by predict_tf.\n",
    "        param shutdown: Shut down the simulation on context exit. Otherwise pause.\n",
    "        \"\"\"\n",
    "        self.sim = vc.launch_experiment('ExDPerceptionChallengeKIT')\n",
    "        self.tfs = tfs_to_add\n",
    "        \n",
    "        self.shutdown = shutdown\n",
    "        \n",
    "        self.solved = False\n",
    "        self.current_view = \"front\"\n",
    "        self.robot_mover = None \n",
    "        self.challenge = None \n",
    "\n",
    "\n",
    "    def set_joints_start(self):\n",
    "        \"\"\"\n",
    "        Moves the robot to a position from which it can overview the challenge setup.\n",
    "        \"\"\"\n",
    "        neck = rospy.Publisher(\"/robot/neck_pitch/pos\", Float64, queue_size=1)\n",
    "        l_elbow = rospy.Publisher(\"/robot/l_elbow/pos\", Float64, queue_size=1)\n",
    "        r_elbow = rospy.Publisher(\"/robot/r_elbow/pos\", Float64, queue_size=1)\n",
    "        \n",
    "        def lower_gaze_and_arms():\n",
    "            while not rospy.is_shutdown():\n",
    "                neck.publish(Float64(-0.8))\n",
    "                l_elbow.publish(Float64(-25.0))\n",
    "                r_elbow.publish(Float64(-25.0))\n",
    "            l_elbow.unregister()\n",
    "            r_elbow.unregister()\n",
    "            \n",
    "        start_new_thread(lower_gaze_and_arms, ())\n",
    "        # The sleeps are necessary to stop the robot from tumbling over\n",
    "        # because it teleports and moves at the same time.\n",
    "        time.sleep(3)\n",
    "        self.side_look()\n",
    "        time.sleep(3)\n",
    "        print(\"Moved robot to start pose\")\n",
    "        \n",
    "    def __enter__(self):\n",
    "        \"\"\"\n",
    "        Start the simulation and move the robot to the starting pose.\n",
    "        Also accquire handles to interact with the challenge.\n",
    "        \"\"\"\n",
    "        self.sim.start()\n",
    "        self.robot_mover = TeleportRobotMover()\n",
    "        self.challenge = ChallengeInteractor()\n",
    "        self.set_joints_start()\n",
    "        # Robot should be in start pose now\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        \"\"\"\n",
    "        Pause the execution of the simulation so the results can be viewed.\n",
    "        \"\"\"\n",
    "        if self.shutdown or exc_type is not None:\n",
    "            print(\"Shutting the simulation down...\")\n",
    "            self.sim.stop()\n",
    "        else:\n",
    "            print(\"Pausing the simulation...\")\n",
    "            self.sim.pause()\n",
    "        \n",
    "        return False\n",
    "            \n",
    "\n",
    "    def front_look(self):\n",
    "        \"\"\"\n",
    "        Moves the robot to the challenge defined start position.\n",
    "        \"\"\"\n",
    "        self.robot_mover.go_to_pose(x=-0.75, y=0., orientation=(0, 0, 1, 0))\n",
    "        self.current_view = \"front\"\n",
    "\n",
    "\n",
    "    def side_look(self):\n",
    "        \"\"\"\n",
    "        Moves the robot to the custom start position.\n",
    "        \"\"\"\n",
    "        orientation = (math.sqrt(0.5), 0, 0, -math.sqrt(0.5))\n",
    "        self.robot_mover.go_to_pose(x=0.4, y=-0.9, orientation=orientation)\n",
    "        self.current_view = \"side\"\n",
    "        \n",
    "    def solve(self, interactive=True):\n",
    "        \"\"\"\n",
    "        Solves the currently started challenge.\n",
    "        \n",
    "        param interactive: Wait for user input between all steps.\n",
    "        \"\"\"\n",
    "        def maybe_get_input(phrase=\"continue\"):\n",
    "            if interactive:\n",
    "                raw_input(\"Insert 'Enter' to {}.\".format(phrase))\n",
    "                \n",
    "        if self.solved:\n",
    "            maybe_get_input(\"reset the simulation\")\n",
    "            self.sim.start()\n",
    "            \n",
    "            # TODO check how this works\n",
    "            @nrp.MapVariable(\"estimate\", initial_value=None, scope=nrp.GLOBAL)\n",
    "            def reset_estimate(estimate):\n",
    "                estimate.value = None\n",
    "            \n",
    "            reset_estimate()\n",
    "            self.challenge.reset()\n",
    "            \n",
    "        \n",
    "        for tf_code in self.tfs.values():\n",
    "            self.sim.add_transfer_function(tf_code)\n",
    "      \n",
    "        time.sleep(2)  # Wait for the TFs to be registered\n",
    "            \n",
    "        maybe_get_input(phrase=\"show the correct mug\")        \n",
    "        self.challenge.show_correct_mug()\n",
    "        maybe_get_input(phrase=\"hide the correct mug\")\n",
    "        self.challenge.hide_correct_mug()\n",
    "        maybe_get_input(phrase=\"shuffle the mugs\")\n",
    "        self.challenge.shuffle()\n",
    "        maybe_get_input(phrase=\"show to correct mug\")\n",
    "        self.challenge.show_correct_mug()   \n",
    "        self.solved = True\n",
    "                \n",
    "        for tf_name in self.tfs.keys():\n",
    "            self.sim.delete_transfer_function(tf_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the solver\n",
    "\n",
    "Now we simply need to create the solver object within its context.\n",
    "I recommend watching the frontend in a separate window.\n",
    "The experiment will pause itself. You can run the solve method multiple times.\n",
    "Please note that in some cases shuffling the mugs will appear to not work, as a random permutation is chosen.\n",
    "In some cases, that permutation is the one the mugs are already in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {\"neuronal_extract_centers\": neuronal_extract_centers,\n",
    "        \"track_green\": track_green,\n",
    "        \"read_retina\": read_retina,\n",
    "        \"find_initial_track\": find_initial_track,\n",
    "        \"predict\": predict}\n",
    "with Solver(tfs_to_add=test,\n",
    "            shutdown=False) as solver:\n",
    "    \n",
    "    # Pass interactive=False to just run everything at once.\n",
    "    solver.solve(interactive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
