{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the thimblerigger\n",
    "\n",
    "First of all, lets disable logging from the virtual coach created here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable global logging from the virtual coach\n",
    "import logging\n",
    "logging.disable(logging.INFO)\n",
    "logging.getLogger('rospy').propagate = False\n",
    "logging.getLogger('rosout').propagate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, I optain a VirtualCoach object as an entry point to the NRP platform.\n",
    "Since I'm working on a local install, we will see a warning message telling us that we have not provided a user name.\n",
    "This is fine for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: [2018-01-30 23:59:11,882 - VirtualCoach] No OIDC username supplied, simulation services will fail if OIDC is enabled in this environment (local).\n"
     ]
    }
   ],
   "source": [
    "# log into the virtual coach, update with your credentials\n",
    "try:\n",
    "    from hbp_nrp_virtual_coach.virtual_coach import VirtualCoach\n",
    "    vc = VirtualCoach(environment='local')\n",
    "except ImportError as e:\n",
    "    print(e)\n",
    "    print(\"You have to start this notebook with the command:\\\n",
    "          cle-virtual-coach jupyter notebook\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I just cluster all imports needed in one global cell so I know where everything is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import math\n",
    "from thread import start_new_thread\n",
    "\n",
    "import cv2\n",
    "import rospy\n",
    "import numpy as np\n",
    "from cv_bridge import CvBridge\n",
    "import hbp_nrp_cle.tf_framework as nrp\n",
    "\n",
    "from gazebo_msgs.msg import ModelState\n",
    "from std_srvs.srv import Trigger, TriggerResponse\n",
    "from gazebo_msgs.srv import GetModelState, SetModelState\n",
    "from std_msgs.msg import UInt32MultiArray, MultiArrayDimension, Float64\n",
    "\n",
    "import thimblerigger_config as tc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving the robot around the simulation\n",
    "\n",
    "I need to move the robot around the simulation to find a spot where it has a good view\n",
    "over the whole challenge setup. Since there may be multiple ways to move around, I define the RobotMover interface,\n",
    "which does nothing by itself, but has methods to move a model through the simulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobotMover(object):\n",
    "    \"\"\"\n",
    "    Interface to move an object through the simulation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name=\"robot\"):\n",
    "        \"\"\"\n",
    "        param model_name: The name in the gazebo simulation of the object that should move.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def go_to_pose(self, x, y, orientation):\n",
    "        \"\"\"\n",
    "        Moves the object to the given coordinates.\n",
    "        \n",
    "        param x: x coordinate to go to.\n",
    "        param y: y coordinate to go to.\n",
    "        param orientation: Quaternion orientation vector.\n",
    "        \"\"\"\n",
    "        raise NotImplemented(\"Please use a subtype of the RobotMover!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is the perception challenge, I will assume that it is ok to just teleport through the \n",
    "simulation. Thus, I build a TeleportRobotMover, which inherits from the RobotMover interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeleportRobotMover(RobotMover):\n",
    "\n",
    "    def __init__(self, model_name=\"robot\"):\n",
    "        \"\"\"\n",
    "        param model_name: The name in the gazebo simulation of the object that should be teleported.\n",
    "        \"\"\"\n",
    "        self.get_position = rospy.ServiceProxy(\"/gazebo/get_model_state\", GetModelState)\n",
    "        self.set_position = rospy.ServiceProxy(\"/gazebo/set_model_state\", SetModelState)\n",
    "        super(TeleportRobotMover, self).__init__(model_name=model_name)\n",
    "\n",
    "    def go_to_pose(self, x, y, orientation):\n",
    "        \"\"\"\n",
    "        Teleports the object to the given coordinates.\n",
    "        \n",
    "        param x: x coordinate (world coordinates) to go to.\n",
    "        param y: y coordinate (world coordinates) to go to.\n",
    "        param orientation: Quaternion orientation vector.\n",
    "        \"\"\"\n",
    "        # Obtain the current pose information, because I do not want\n",
    "        # to change scale, twist, z-coordinate etc.\n",
    "        current_robot_pose = self.get_position(self.model_name, \"\")\n",
    "        new_state = ModelState()\n",
    "        new_state.model_name = self.model_name\n",
    "        new_state.pose = current_robot_pose.pose\n",
    "        new_state.scale = current_robot_pose.scale\n",
    "        new_state.twist = current_robot_pose.twist\n",
    "        new_state.pose.position.x = x\n",
    "        new_state.pose.position.y = y\n",
    "        new_state.pose.orientation.x = orientation[1]\n",
    "        new_state.pose.orientation.y = orientation[2]\n",
    "        new_state.pose.orientation.z = orientation[3]\n",
    "        new_state.pose.orientation.w = orientation[0]\n",
    "        new_state.reference_frame = \"world\"\n",
    "        self.set_position(new_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with the challenge interface\n",
    "\n",
    "I also need a convenient way to interact with the services provided by the thimblerigger challenge. \n",
    "I simply store handles to the ServiceProxies in a wrapper object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChallengeInteractor(object):\n",
    "\n",
    "    \"\"\"\n",
    "    Interface to interact with the thimblerigger challenge.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Accquire persistent handles to all relevant services\n",
    "        print(\"Waiting for show mug service...\")\n",
    "        rospy.wait_for_service(tc.thimblerigger_show_correct_service, 10)\n",
    "        print(\"Show mug service available.\")\n",
    "        \n",
    "        print(\"Waiting for hide mug service...\")\n",
    "        rospy.wait_for_service(tc.thimblerigger_hide_correct_service, 10)\n",
    "        print(\"Hide mug service available.\")\n",
    "        \n",
    "        print(\"Waiting for shuffle service...\")\n",
    "        rospy.wait_for_service(tc.thimblerigger_shuffle_service, 10)\n",
    "        print(\"Shuffle service available.\")\n",
    "        \n",
    "        print(\"Waiting for reset service...\")\n",
    "        rospy.wait_for_service(tc.thimblerigger_reset_service, 10)\n",
    "        print(\"Reset service available.\")\n",
    "        \n",
    "        print(\"All thimblerigger services found.\")                       \n",
    "        self.show_correct_mug = rospy.ServiceProxy(tc.thimblerigger_show_correct_service, Trigger)\n",
    "        self.hide_correct_mug = rospy.ServiceProxy(tc.thimblerigger_hide_correct_service, Trigger)\n",
    "        self.shuffle = rospy.ServiceProxy(tc.thimblerigger_shuffle_service, Trigger)\n",
    "        self.reset = rospy.ServiceProxy(tc.thimblerigger_reset_service, Trigger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the puzzle\n",
    "\n",
    "Let's create a solver, which actually beats the challenge. For this, we need two transfer functions.\n",
    "One to visualize what the robot is predicting, and one to make the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_guess = \"\"\"\n",
    "import numpy as np\n",
    "\n",
    "@nrp.MapSpikeSink(\"actors\", nrp.map_neurons(range(0, 3), lambda i: nrp.brain.actors[i]), nrp.population_rate)\n",
    "@nrp.Robot2Neuron()\n",
    "def visualize_guess(t, actors):\n",
    "    pass\n",
    "    #clientLogger.info(actors.rate)\n",
    "    #clientLogger.info(np.argmax(actors.rate))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = \"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sensor_msgs\n",
    "\n",
    "@nrp.MapRobotSubscriber(\"img_msg\", Topic(\"/icub_model/left_eye_camera/image_raw\", sensor_msgs.msg.Image))\n",
    "@nrp.MapVariable(\"area_grid\", initial_value=None, scope=nrp.GLOBAL)\n",
    "@nrp.MapVariable(\"estimate\", initial_value=None, scope=nrp.GLOBAL)\n",
    "@nrp.MapSpikeSource(\"grid_neurons\", nrp.map_neurons(range(0, 9), lambda i: nrp.brain.sensors[i]), nrp.poisson)\n",
    "@nrp.Robot2Neuron()\n",
    "def predict(t, img_msg, area_grid, estimate, grid_neurons):\n",
    "    \n",
    "    if img_msg.value is None:\n",
    "        return\n",
    "        \n",
    "    img = CvBridge().imgmsg_to_cv2(img_msg.value, \"bgr8\")\n",
    "    most_vibrant_channel = np.argmax(img, axis=2)\n",
    "    \n",
    "    # Filter red \n",
    "    img[most_vibrant_channel != 2] = 0\n",
    "    img[img[:,:,2] < 150] = 0\n",
    "    red = img[:, :, 2]\n",
    "    _, thresh = cv2.threshold(red, 150, 255, 0)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    thresh = cv2.erode(thresh, kernel,iterations = 1)\n",
    "    im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    contour_thresh = 50\n",
    "    contours = [c for c in contours if cv2.contourArea(c) > contour_thresh]\n",
    "\n",
    "    moments = [cv2.moments(c) for c in contours]\n",
    "    centers = sorted([(int(M['m10']/M['m00']), int(M['m01']/M['m00'])) for M in moments])\n",
    "    center_points = np.array(centers)\n",
    "    \n",
    "    if center_points is None or center_points.shape != (3, 2):\n",
    "        return\n",
    "        \n",
    "    if area_grid.value is None:\n",
    "\n",
    "        x_intervals = [int(center_points[0, 0] + 0.5 * \\\n",
    "                        (center_points[1, 0] - center_points[0, 0])),\n",
    "                       int(center_points[1, 0] + 0.5 * \\\n",
    "                        (center_points[2, 0] - center_points[1, 0]))]\n",
    "        y_intervals = []\n",
    "        for cnt in contours:\n",
    "            (_,y),radius = cv2.minEnclosingCircle(cnt)\n",
    "            y_intervals.extend([int(y + 1.5 * radius), int(y - 1.5 * radius)])\n",
    "        y_intervals = [min(y_intervals), max(y_intervals)]\n",
    "        \n",
    "        area_grid.value = x_intervals, y_intervals\n",
    "        \n",
    "    if estimate.value is None:\n",
    "        y_coords = np.transpose(center_points)[1]\n",
    "        #diffs = y_coords[:, None] - y_coords\n",
    "        #diffs = np.abs(diffs)\n",
    "        #diffs = diffs[np.triu(diffs) > 0]\n",
    "        mi = np.min(y_coords)\n",
    "        miid = np.argmin(y_coords)\n",
    "        no_mi = np.delete(y_coords, miid)\n",
    "        diffs = np.abs(no_mi - mi)\n",
    "        clientLogger.info(diffs)\n",
    "        if np.all(diffs > 20):\n",
    "            clientLogger.info(\"found track {}\".format(miid))\n",
    "            estimate.value = center_points[miid]\n",
    "        else:\n",
    "            return\n",
    "            # Don't know which mug is correct yet\n",
    "\n",
    "    # We now have the last position of the correct mug\n",
    "    center_diffs = np.linalg.norm(center_points - estimate.value, axis=-1)\n",
    "    correct_id = np.argmin(center_diffs)\n",
    "    estimate.value = center_points[correct_id]\n",
    "    clientLogger.info(correct_id)\n",
    "        \n",
    "    def map_border(idx, x_or_y):\n",
    "        if idx == 0:\n",
    "            return slice(0, area_grid.value[x_or_y][0])\n",
    "        elif idx == 1:\n",
    "            return slice(area_grid.value[x_or_y][0], area_grid.value[0][1])\n",
    "        elif idx == 2:\n",
    "            return slice(area_grid.value[x_or_y][1], -1)\n",
    "         \n",
    "    locations = np.zeros((3,3))\n",
    "    if area_grid.value is not None:\n",
    "        for center in center_points:\n",
    "            x_idx = np.searchsorted(area_grid.value[0], center[0])\n",
    "            y_idx = np.searchsorted(area_grid.value[1], center[1])\n",
    "            img_part = red[map_border(y_idx, x_or_y=1), map_border(x_idx, x_or_y=0)] > 125\n",
    "            locations[y_idx, x_idx] = np.sum(img_part) / np.sum(np.ones_like(red)) * 100.\n",
    "    locations[1, correct_id] = 100.\n",
    "                \n",
    "    grid_neurons.rate = locations.flatten()\n",
    "    #clientLogger.info(locations)\n",
    "    \n",
    "    \n",
    "    return CvBridge().cv2_to_imgmsg(img, 'bgr8')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    Solver for the thimblerigger challenge.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, predict_tf, visualize_tf=None, shutdown=False):\n",
    "        \"\"\"\n",
    "        param predict_tf: Transfer function that predicts which mug contains the ball.\n",
    "        param visualize_tf: Transfer function that visualizes the predictions made by predict_tf.\n",
    "        param shutdown: Shut down the simulation on context exit. Otherwise pause.\n",
    "        \"\"\"\n",
    "        self.sim = vc.launch_experiment('ExDPerceptionChallengeKIT')\n",
    "        self.predict_tf = predict_tf\n",
    "        self.visualize_tf = visualize_tf\n",
    "        \n",
    "        self.shutdown = shutdown\n",
    "        \n",
    "        self.solved = False\n",
    "        self.current_view = \"front\"\n",
    "        self.robot_mover = None \n",
    "        self.challenge = None \n",
    "\n",
    "\n",
    "    def set_joints_start(self):\n",
    "        \"\"\"\n",
    "        Moves the robot to a position from which it can overview the challenge setup.\n",
    "        \"\"\"\n",
    "        neck = rospy.Publisher(\"/robot/neck_pitch/pos\", Float64, queue_size=1)\n",
    "        l_elbow = rospy.Publisher(\"/robot/l_elbow/pos\", Float64, queue_size=1)\n",
    "        r_elbow = rospy.Publisher(\"/robot/r_elbow/pos\", Float64, queue_size=1)\n",
    "        \n",
    "        def lower_gaze_and_arms():\n",
    "            while not rospy.is_shutdown():\n",
    "                neck.publish(Float64(-0.8))\n",
    "                l_elbow.publish(Float64(-25.0))\n",
    "                r_elbow.publish(Float64(-25.0))\n",
    "            l_elbow.unregister()\n",
    "            r_elbow.unregister()\n",
    "            \n",
    "        start_new_thread(lower_gaze_and_arms, ())\n",
    "        # The sleeps are necessary to stop the robot from tumbling over\n",
    "        # because it teleports and moves at the same time.\n",
    "        time.sleep(3)\n",
    "        self.side_look()\n",
    "        time.sleep(3)\n",
    "        print(\"Moved robot to start pose\")\n",
    "        \n",
    "    def __enter__(self):\n",
    "        \"\"\"\n",
    "        Start the simulation and move the robot to the starting pose.\n",
    "        Also accquire handles to interact with the challenge.\n",
    "        \"\"\"\n",
    "        self.sim.start()\n",
    "        self.robot_mover = TeleportRobotMover()\n",
    "        self.challenge = ChallengeInteractor()\n",
    "        self.set_joints_start()\n",
    "        # Robot should be in start pose now\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        \"\"\"\n",
    "        Pause the execution of the simulation so the results can be viewed.\n",
    "        \"\"\"\n",
    "        if self.shutdown or exc_type is not None:\n",
    "            print(\"Shutting the simulation down...\")\n",
    "            self.sim.stop()\n",
    "        else:\n",
    "            print(\"Pausing the simulation...\")\n",
    "            self.sim.pause()\n",
    "        \n",
    "        return False\n",
    "            \n",
    "\n",
    "    def front_look(self):\n",
    "        \"\"\"\n",
    "        Moves the robot to the challenge defined start position.\n",
    "        \"\"\"\n",
    "        self.robot_mover.go_to_pose(x=-0.75, y=0., orientation=(0, 0, 1, 0))\n",
    "        self.current_view = \"front\"\n",
    "\n",
    "\n",
    "    def side_look(self):\n",
    "        \"\"\"\n",
    "        Moves the robot to the custom start position.\n",
    "        \"\"\"\n",
    "        orientation = (math.sqrt(0.5), 0, 0, -math.sqrt(0.5))\n",
    "        self.robot_mover.go_to_pose(x=0.4, y=-0.9, orientation=orientation)\n",
    "        self.current_view = \"side\"\n",
    "        \n",
    "    def solve(self, interactive=True):\n",
    "        \"\"\"\n",
    "        Solves the currently started challenge.\n",
    "        \n",
    "        param interactive: Wait for user input between all steps.\n",
    "        \"\"\"\n",
    "        def maybe_get_input(phrase=\"continue\"):\n",
    "            if interactive:\n",
    "                raw_input(\"Insert 'Enter' to {}.\".format(phrase))\n",
    "                \n",
    "        if self.solved:\n",
    "            maybe_get_input(\"reset the simulation\")\n",
    "            self.sim.start()\n",
    "            \n",
    "            # TODO check how this works\n",
    "            @nrp.MapVariable(\"estimate\", initial_value=None, scope=nrp.GLOBAL)\n",
    "            def reset_estimate(estimate):\n",
    "                estimate.value = None\n",
    "            \n",
    "            reset_estimate()\n",
    "            self.challenge.reset()\n",
    "            \n",
    "            \n",
    "        self.sim.add_transfer_function(self.predict_tf)\n",
    "        if self.visualize_tf is not None:\n",
    "            self.sim.add_transfer_function(self.visualize_tf)\n",
    "        time.sleep(2)  # Wait for the TFs to be registered\n",
    "            \n",
    "        maybe_get_input(phrase=\"show the correct mug\")        \n",
    "        self.challenge.show_correct_mug()\n",
    "        maybe_get_input(phrase=\"hide the correct mug\")\n",
    "        self.challenge.hide_correct_mug()\n",
    "        maybe_get_input(phrase=\"shuffle the mugs\")\n",
    "        self.challenge.shuffle()\n",
    "        maybe_get_input(phrase=\"show to correct mug\")\n",
    "        self.challenge.show_correct_mug()   \n",
    "        self.solved = True\n",
    "        \n",
    "        # TODO do not hardcode these names\n",
    "        self.sim.delete_transfer_function(\"predict\")\n",
    "        if self.visualize_tf is not None:\n",
    "            self.sim.delete_transfer_function(\"visualize_guess\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the solver\n",
    "\n",
    "Now we simply need to create the solver object within its context.\n",
    "I recommend watching the frontend in a separate window.\n",
    "The experiment will pause itself. You can run the solve method multiple times.\n",
    "Please note that in some cases shuffling the mugs will appear to not work, as a random permutation is chosen.\n",
    "In some cases, that permutation is the one the mugs are already in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Solver(predict_tf=predict,\n",
    "            visualize_tf=visualize_guess,\n",
    "            shutdown=False) as solver:\n",
    "    \n",
    "    # Pass interactive=False to just run everything at once.\n",
    "    solver.solve(interactive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
